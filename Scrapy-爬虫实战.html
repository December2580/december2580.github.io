<!DOCTYPE html><html lang="zh-CN"><head><meta charset="UTF-8"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=2"><meta name="theme-color" content="#222"><meta name="generator" content="Hexo 4.0.0"><meta name="baidu-site-verification" content="touy7TFMxR"><link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png"><link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png"><link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png"><link rel="mask-icon" href="/images/logo.svg" color="#222"><link rel="alternate" href="/atom.xml" title="小宅的博客" type="application/atom+xml"><link rel="stylesheet" href="/css/main.css"><link rel="stylesheet" href="/lib/font-awesome/css/font-awesome.min.css"><link rel="stylesheet" href="//cdn.jsdelivr.net/gh/fancyapps/fancybox@3/dist/jquery.fancybox.min.css"><script id="hexo-configurations">var NexT=window.NexT||{},CONFIG={root:"/",scheme:"Gemini",version:"7.5.0",exturl:!1,sidebar:{position:"left",display:"post",offset:12,onmobile:!0},copycode:{enable:!0,show_result:!0,style:null},back2top:{enable:!0,sidebar:!1,scrollpercent:!1},bookmark:{enable:!1,color:"#222",save:"auto"},fancybox:!0,mediumzoom:!1,lazyload:!1,pangu:!1,algolia:{appID:"",apiKey:"",indexName:"",hits:{per_page:10},labels:{input_placeholder:"Search for Posts",hits_empty:"We didn't find any results for the search: ${query}",hits_stats:"${hits} results found in ${time} ms"}},localsearch:{enable:!0,trigger:"auto",top_n_per_article:1,unescape:!1,preload:!1},path:"search.xml",motion:{enable:!0,async:!1,transition:{post_block:"fadeIn",post_header:"slideDownIn",post_body:"slideDownIn",coll_header:"slideLeftIn",sidebar:"slideUpIn"}},translation:{copy_button:"复制",copy_success:"复制成功",copy_failure:"复制失败"},sidebarPadding:40}</script><meta name="description" content="&amp;emsp;&amp;emsp;最近在看爬虫，跟着Scrapy的官方文档实例走了一遍，等自己想爬别的网站的时候，发现还是有点问题，于是网上找了个教程，自己跟着做了一遍，然后换了一个网站，爬一下别的数据，现在做一下记录，由于也是刚刚接触，所以在一些使用上可能还存在误区，欢迎大家批评指正。&amp;emsp;&amp;emsp;http:&#x2F;&#x2F;www.weather.com.cn&#x2F;weather&#x2F;101250101.shtml"><meta name="keywords" content="Scrapy,爬虫"><meta property="og:type" content="article"><meta property="og:title" content="Scrapy 爬虫实战"><meta property="og:url" content="https:&#x2F;&#x2F;december2580.github.io&#x2F;Scrapy-%E7%88%AC%E8%99%AB%E5%AE%9E%E6%88%98.html"><meta property="og:site_name" content="小宅的博客"><meta property="og:description" content="&amp;emsp;&amp;emsp;最近在看爬虫，跟着Scrapy的官方文档实例走了一遍，等自己想爬别的网站的时候，发现还是有点问题，于是网上找了个教程，自己跟着做了一遍，然后换了一个网站，爬一下别的数据，现在做一下记录，由于也是刚刚接触，所以在一些使用上可能还存在误区，欢迎大家批评指正。&amp;emsp;&amp;emsp;http:&#x2F;&#x2F;www.weather.com.cn&#x2F;weather&#x2F;101250101.shtml"><meta property="og:locale" content="zh-CN"><meta property="og:image" content="http:&#x2F;&#x2F;q0uiq01q3.bkt.clouddn.com&#x2F;3_1.png"><meta property="og:image" content="http:&#x2F;&#x2F;q0uiq01q3.bkt.clouddn.com&#x2F;3_2.png"><meta property="og:image" content="http:&#x2F;&#x2F;q0uiq01q3.bkt.clouddn.com&#x2F;3_3.png"><meta property="og:image" content="http:&#x2F;&#x2F;q0uiq01q3.bkt.clouddn.com&#x2F;3_4.png"><meta property="og:image" content="http:&#x2F;&#x2F;q0uiq01q3.bkt.clouddn.com&#x2F;3_5.png"><meta property="og:image" content="http:&#x2F;&#x2F;q0uiq01q3.bkt.clouddn.com&#x2F;3_6.png"><meta property="og:image" content="http:&#x2F;&#x2F;q0uiq01q3.bkt.clouddn.com&#x2F;3_7.png"><meta property="og:updated_time" content="2019-11-15T13:35:20.629Z"><meta name="twitter:card" content="summary"><meta name="twitter:image" content="http:&#x2F;&#x2F;q0uiq01q3.bkt.clouddn.com&#x2F;3_1.png"><link rel="canonical" href="https://december2580.github.io/Scrapy-%E7%88%AC%E8%99%AB%E5%AE%9E%E6%88%98.html"><script id="page-configurations">CONFIG.page={sidebar:"",isHome:!1,isPost:!0,isPage:!1,isArchive:!1}</script><title>Scrapy 爬虫实战 | 小宅的博客</title><noscript><style>.sidebar-inner,.use-motion .brand,.use-motion .collection-header,.use-motion .comments,.use-motion .menu-item,.use-motion .pagination,.use-motion .post-block,.use-motion .post-body,.use-motion .post-header{opacity:initial}.use-motion .site-subtitle,.use-motion .site-title{opacity:initial;top:initial}.use-motion .logo-line-before i{left:initial}.use-motion .logo-line-after i{right:initial}</style></noscript></head><body itemscope itemtype="http://schema.org/WebPage"><div class="container use-motion"><div class="headband"></div><header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="header-inner"><div class="site-brand-container"><div class="site-meta"><div><a href="/" class="brand" rel="start"><span class="logo-line-before"><i></i></span> <span class="site-title">小宅的博客</span><span class="logo-line-after"><i></i></span></a></div><p class="site-subtitle">你想批评指点四周风景，你首先要爬上屋顶。</p></div><div class="site-nav-toggle"><div class="toggle" aria-label="切换导航栏"><span class="toggle-line toggle-line-first"></span><span class="toggle-line toggle-line-middle"></span><span class="toggle-line toggle-line-last"></span></div></div></div><nav class="site-nav"><ul id="menu" class="menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-fw fa-home"></i> 首页</a></li><li class="menu-item menu-item-about"><a href="/about/" rel="section"><i class="fa fa-fw fa-user"></i> 关于</a></li><li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="fa fa-fw fa-tags"></i> 标签</a></li><li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="fa fa-fw fa-th"></i> 分类</a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-fw fa-archive"></i> 归档</a></li><li class="menu-item menu-item-search"><a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i> 搜索</a></li></ul></nav><div class="site-search"><div class="popup search-popup"><div class="search-header"><span class="search-icon"><i class="fa fa-search"></i></span><div class="search-input-container"> <input autocomplete="off" autocorrect="off" autocapitalize="none" placeholder="搜索..." spellcheck="false" type="text" id="search-input"></div><span class="popup-btn-close"><i class="fa fa-times-circle"></i></span></div><div id="search-result"></div></div><div class="search-pop-overlay"></div></div></div></header><div class="back-to-top"><i class="fa fa-arrow-up"></i> <span>0%</span></div><main class="main"><div class="main-inner"><div class="content-wrap"><div class="content"><div class="posts-expand"><article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN"><link itemprop="mainEntityOfPage" href="https://december2580.github.io/Scrapy-%E7%88%AC%E8%99%AB%E5%AE%9E%E6%88%98.html"><span hidden itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="image" content="/images/header.jpg"><meta itemprop="name" content="宅"><meta itemprop="description" content="记录学习的点滴。"></span><span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="小宅的博客"></span><header class="post-header"><h1 class="post-title" itemprop="name headline"> Scrapy 爬虫实战</h1><div class="post-meta"><span class="post-meta-item"><span class="post-meta-item-icon"><i class="fa fa-calendar-o"></i></span> <span class="post-meta-item-text">发表于</span> <time title="创建时间：2019-11-15 20:16:36 / 修改时间：21:35:20" itemprop="dateCreated datePublished" datetime="2019-11-15T20:16:36+08:00">2019-11-15</time></span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="fa fa-folder-o"></i></span> <span class="post-meta-item-text">分类于</span> <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/%E5%AD%A6%E4%B9%A0/" itemprop="url" rel="index"><span itemprop="name">学习</span></a></span></span><span class="post-meta-item" title="阅读次数" id="busuanzi_container_page_pv" style="display:none"><span class="post-meta-item-icon"><i class="fa fa-eye"></i></span> <span class="post-meta-item-text">阅读次数：</span><span id="busuanzi_value_page_pv"></span></span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="fa fa-comment-o"></i></span> <span class="post-meta-item-text">Valine：</span><a title="valine" href="/Scrapy-%E7%88%AC%E8%99%AB%E5%AE%9E%E6%88%98.html#comments" itemprop="discussionUrl"><span class="post-comments-count valine-comment-count" data-xid="/Scrapy-%E7%88%AC%E8%99%AB%E5%AE%9E%E6%88%98.html" itemprop="commentCount"></span></a></span><br><span class="post-meta-item" title="本文字数"><span class="post-meta-item-icon"><i class="fa fa-file-word-o"></i></span> <span class="post-meta-item-text">本文字数：</span> <span>2.3k</span></span><span class="post-meta-item" title="阅读时长"><span class="post-meta-item-icon"><i class="fa fa-clock-o"></i></span> <span class="post-meta-item-text">阅读时长 &asymp;</span> <span>2 分钟</span></span></div></header><div class="post-body" itemprop="articleBody"><p>&emsp;&emsp;最近在看爬虫，跟着Scrapy的官方文档实例走了一遍，等自己想爬别的网站的时候，发现还是有点问题，于是网上找了个教程，自己跟着做了一遍，然后换了一个网站，爬一下别的数据，现在做一下记录，由于也是刚刚接触，所以在一些使用上可能还存在误区，欢迎大家批评指正。<br>&emsp;&emsp;<a href="http://www.weather.com.cn/weather/101250101.shtml" target="_blank" rel="noopener">http://www.weather.com.cn/weather/101250101.shtml</a><br>&emsp;&emsp;这是我们爬取信息的网址，爬取长沙未来七天的天气情况。</p><p>&emsp;&emsp;环境：windows10，python3.6，scrapy1.8，anaconda，chorme<br>##创建scrapy项目并生成相应的文件<br>&emsp;&emsp;首先选择一个你的项目位置，然后在该位置下打开cmd，执行 <strong>scrapy start testSpider</strong> ,初始化一个scrapy项目，其中最后一个字段是项目名称，效果如下：<br><img src="http://q0uiq01q3.bkt.clouddn.com/3_1.png" alt=""></p><p>&emsp;&emsp;在PyCharm中可以查看一下目录结构：<br><img src="http://q0uiq01q3.bkt.clouddn.com/3_2.png" alt=""></p><p>&emsp;&emsp;这些文件的主要作用在官方文档里都有介绍。<br>&emsp;&emsp;然后我们回到cmd，根据提示进行操作，cd testSpider 切换到项目的文件夹下，执行 <strong>scrapy genspider example example.com</strong>，这里example是你的爬虫的name，是他的唯一标示，不同的爬虫的name必须不同，example.com是允许爬取的域。<br>&emsp;&emsp;我们执行&emsp;<strong>scrapy genspider weather weather.com.cn</strong>&emsp;创建一个爬虫的执行文件。执行完之后可以PyCharm中看到在spiders的文件夹下生成了一个weather.py文件：<br><img src="http://q0uiq01q3.bkt.clouddn.com/3_3.png" alt=""></p><p>&emsp;&emsp;文件包含一些自动生成的代码。<br>##分析需要爬取的网页并编码<br>&emsp;&emsp;我们打开那个网址，ctrl+shift+i，检查，一步一步找到我们需要的信息，最终发现，这些天气的信息都在一个如图所示的位置。<br><img src="http://q0uiq01q3.bkt.clouddn.com/3_4.png" alt=""></p><p>&emsp;&emsp;找到这个位置之后，我们点开一天的，信息如下图所示，因为我是在晚上写的这篇博客，看的又是第一天，所以只有最低温度，没有最高温度，我们提取 天，天气，最低温和最高温这4项信息。<br><img src="http://q0uiq01q3.bkt.clouddn.com/3_5.png" alt=""></p><p>&emsp;&emsp;这时候，我们需要打开项目中的items.py，写一个类来保存（封装）我们的这些数据，如下图所示。<br><img src="http://q0uiq01q3.bkt.clouddn.com/3_6.png" alt=""></p><p>&emsp;&emsp;下面需要我们的爬虫登场了，打开spider下的weather.py，我们下面使用BeautifulSoup来进行数据的提取。我直接贴上代码喽。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> scrapy</span><br><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line"><span class="keyword">from</span> weatherSpider.items <span class="keyword">import</span> WeatherItem</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">WeahterSpider</span><span class="params">(scrapy.Spider)</span>:</span></span><br><span class="line">    name = <span class="string">'weather'</span>		<span class="comment">#spider的名字，唯一标志</span></span><br><span class="line">    allowed_domains = [<span class="string">'weather.com.cn'</span>]		<span class="comment">#允许爬取的域</span></span><br><span class="line">    start_urls = [<span class="string">'http://www.weather.com.cn/weather/101250101.shtml'</span>]	<span class="comment">#开始爬取的起点</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">parse</span><span class="params">(self,response)</span>:</span></span><br><span class="line">        html = response.text		<span class="comment">#获得爬到的网页的HTML代码</span></span><br><span class="line"></span><br><span class="line">        soup = BeautifulSoup(html,<span class="string">'lxml'</span>)	<span class="comment">#创建一个soup对象</span></span><br><span class="line">        weather = WeatherItem()			<span class="comment">#创建一个weatherItem对象，存储爬取的信息</span></span><br><span class="line">        div_7d = soup.find(<span class="string">'div'</span>,class_=<span class="string">'c7d'</span>)	<span class="comment">#找到class为c7d的标签</span></span><br><span class="line">        <span class="keyword">if</span> div_7d <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:					<span class="comment">#如果存在</span></span><br><span class="line">            ul = div_7d.find(<span class="string">'ul'</span>)				<span class="comment">#逐步缩小范围</span></span><br><span class="line">            <span class="keyword">if</span> ul <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">                <span class="keyword">for</span> li <span class="keyword">in</span> ul.find_all(<span class="string">'li'</span>):</span><br><span class="line">                    <span class="keyword">if</span> li <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">                        weather[<span class="string">'day'</span>] = li.find(<span class="string">'h1'</span>).get_text()		<span class="comment">#取标签包含的数据</span></span><br><span class="line">                        weather[<span class="string">'wea'</span>] = li.find(<span class="string">'p'</span>).get_text()</span><br><span class="line">                        span = li.find(<span class="string">'span'</span>)</span><br><span class="line">                        <span class="keyword">if</span> span <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">                            weather[<span class="string">'highest'</span>] = span.get_text()</span><br><span class="line">                        weather[<span class="string">'lowest'</span>] = li.find(<span class="string">'i'</span>).get_text()</span><br><span class="line">                        print(weather)</span><br></pre></td></tr></table></figure><p>&emsp;&emsp;整体的思想就是一步一步缩小范围，逐步获得我们需要的数据。<br>##entryPoint.py 便捷启动<br>&emsp;&emsp;编写完上面的代码，在scrapy项目的根目录下执行&emsp;<strong>scrapy crawl weather</strong>&emsp;就能为了能够运行爬虫程序了，但是为了更加方便的启动爬虫，我们可以在项目根目录下编写一个entrypoint.py文件，直接在PyCharm中启动爬虫，</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> scrapy.cmdline <span class="keyword">import</span> execute</span><br><span class="line"></span><br><span class="line">execute([<span class="string">'scrapy'</span>,<span class="string">'crawl'</span>,<span class="string">'weather'</span>])</span><br></pre></td></tr></table></figure><p>&emsp;&emsp;执行之后就能够看到爬取的数据的结果了：<br><img src="http://q0uiq01q3.bkt.clouddn.com/3_7.png" alt=""></p><p>&emsp;&emsp;到这，这个简单的scrapy爬虫实战就结束了….确实很简单，但也会有成就感。</p></div><div><div><div style="text-align:center;color:#555;font-size:14px">----------------------------本文已结束，感谢阅读。----------------------------</div></div></div><footer class="post-footer"><div class="post-tags"><a href="/tags/Scrapy/" rel="tag"><i class="fa fa-tag"></i> Scrapy</a><a href="/tags/%E7%88%AC%E8%99%AB/" rel="tag"><i class="fa fa-tag"></i> 爬虫</a></div><div class="post-nav"><div class="post-nav-next post-nav-item"></div><span class="post-nav-divider"></span><div class="post-nav-prev post-nav-item"> <a href="/git-git-coding-net-Permission-denied-publickey-%E7%9A%84%E8%A7%A3%E5%86%B3%E5%8A%9E%E6%B3%95.html" rel="next" title="git@git.coding.net: Permission denied (publickey)的解决办法">git@git.coding.net: Permission denied (publickey)的解决办法<i class="fa fa-chevron-right"></i></a></div></div></footer></article></div></div><div class="comments" id="comments"></div></div><div class="toggle sidebar-toggle"><span class="toggle-line toggle-line-first"></span><span class="toggle-line toggle-line-middle"></span><span class="toggle-line toggle-line-last"></span></div><aside class="sidebar"><div class="sidebar-inner"><ul class="sidebar-nav motion-element"><li class="sidebar-nav-toc"> 文章目录</li><li class="sidebar-nav-overview"> 站点概览</li></ul><div class="post-toc-wrap sidebar-panel"></div><div class="site-overview-wrap sidebar-panel"><div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person"> <a href="/"><img class="site-author-image" itemprop="image" alt="宅" src="/images/header.jpg"></a><p class="site-author-name" itemprop="name">宅</p><div class="site-description" itemprop="description">记录学习的点滴。</div></div><div class="site-state-wrap motion-element"><nav class="site-state"><div class="site-state-item site-state-posts"> <a href="/archives/"><span class="site-state-item-count">3</span> <span class="site-state-item-name">日志</span></a></div><div class="site-state-item site-state-categories"> <a href="/categories/"><span class="site-state-item-count">2</span> <span class="site-state-item-name">分类</span></a></div><div class="site-state-item site-state-tags"> <a href="/tags/"><span class="site-state-item-count">4</span> <span class="site-state-item-name">标签</span></a></div></nav></div><div class="feed-link motion-element"><a href="/atom.xml" rel="alternate"><i class="fa fa-rss"></i> RSS</a></div><div class="links-of-blogroll motion-element"><div class="links-of-blogroll-title"><i class="fa fa-fw fa-users"></i> 我的好友</div><ul class="links-of-blogroll-list"><li class="links-of-blogroll-item"> <a href="https://softwarex4.github.io/" title="https:&#x2F;&#x2F;softwarex4.github.io" rel="noopener" target="_blank">x4</a></li></ul></div></div></div></aside><div id="sidebar-dimmer"></div></div></main><footer class="footer"><div class="footer-inner"><div class="copyright"> &copy; <span itemprop="copyrightYear">2019</span><span class="with-love"><i class="fa fa-heart"></i></span> <span class="author" itemprop="copyrightHolder">宅</span> <span class="post-meta-divider">|</span><span class="post-meta-item-icon"><i class="fa fa-area-chart"></i></span> <span title="站点总字数">4k</span> <span class="post-meta-divider">|</span><span class="post-meta-item-icon"><i class="fa fa-coffee"></i></span> <span title="站点阅读时长">4 分钟</span></div><div id="days"></div><script>function show_date_time(){window.setTimeout("show_date_time()",1e3),BirthDay=new Date("11/7/2019 15:13:14"),today=new Date,timeold=today.getTime()-BirthDay.getTime(),sectimeold=timeold/1e3,secondsold=Math.floor(sectimeold),msPerDay=864e5,e_daysold=timeold/msPerDay,daysold=Math.floor(e_daysold),e_hrsold=24*(e_daysold-daysold),hrsold=setzero(Math.floor(e_hrsold)),e_minsold=60*(e_hrsold-hrsold),minsold=setzero(Math.floor(60*(e_hrsold-hrsold))),seconds=setzero(Math.floor(60*(e_minsold-minsold))),document.getElementById("days").innerHTML="本站已安全运行"+daysold+"天"+hrsold+"小时"+minsold+"分"+seconds+"秒"}function setzero(e){return e<10&&(e="0"+e),e}show_date_time()</script><div class="busuanzi-count"><script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><span class="post-meta-item" id="busuanzi_container_site_uv" style="display:none"><span class="post-meta-item-icon"><i class="fa fa-user"></i></span><span class="site-uv" title="总访客量"><span id="busuanzi_value_site_uv"></span></span></span> <span class="post-meta-divider">|</span><span class="post-meta-item" id="busuanzi_container_site_pv" style="display:none"><span class="post-meta-item-icon"><i class="fa fa-eye"></i></span><span class="site-pv" title="总访问量"><span id="busuanzi_value_site_pv"></span></span></span></div></div></footer></div><script src="/lib/anime.min.js"></script><script src="//cdn.jsdelivr.net/npm/jquery@3/dist/jquery.min.js"></script><script src="//cdn.jsdelivr.net/gh/fancyapps/fancybox@3/dist/jquery.fancybox.min.js"></script><script src="/lib/velocity/velocity.min.js"></script><script src="/lib/velocity/velocity.ui.min.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/schemes/pisces.js"></script><script src="/js/next-boot.js"></script><script>!function(){var t=document.createElement("script"),e=window.location.protocol.split(":")[0];t.src="https"===e?"https://zz.bdstatic.com/linksubmit/push.js":"http://push.zhanzhang.baidu.com/push.js";var s=document.getElementsByTagName("script")[0];s.parentNode.insertBefore(t,s)}()</script><script src="/js/local-search.js"></script><script>
NexT.utils.getScript('//unpkg.com/valine/dist/Valine.min.js', () => {
  var GUEST = ['nick', 'mail', 'link'];
  var guest = 'nick,mail';
  guest = guest.split(',').filter(item => {
    return GUEST.includes(item);
  });
  new Valine({
    el: '#comments',
    verify: false,
    notify: true,
    appId: '2YGGBdyJ6wGs0xRYTKiOLo9H-gzGzoHsz',
    appKey: 'wyY7N2pUsiQXoVvhXPM2udUy',
    placeholder: "输入你的昵称和邮箱，快来评论吧~",
    avatar: 'robohash',
    meta: guest,
    pageSize: '10' || 10,
    visitor: false,
    lang: 'zh-cn' || 'zh-cn',
    path: location.pathname,
    recordIP: false,
    serverURLs: ''
  });
}, window.Valine);
</script><script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({pluginRootPath:"live2dw/",pluginJsPath:"lib/",pluginModelPath:"assets/",model:{scale:1,hHeadPos:.5,vHeadPos:.618,jsonPath:"/live2dw/assets/chitose.model.json"},display:{superSample:2,width:200,height:400,position:"right",hOffset:0,vOffset:-50},mobile:{show:!0,scale:.5},react:{opacityDefault:.7,opacityOnHover:.2},log:!1,tagMode:!1})</script></body></html>