<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>Scrapy 爬虫实战</title>
    <url>/Scrapy-%E7%88%AC%E8%99%AB%E5%AE%9E%E6%88%98.html</url>
    <content><![CDATA[<p>&emsp;&emsp;最近在看爬虫，跟着Scrapy的官方文档实例走了一遍，等自己想爬别的网站的时候，发现还是有点问题，于是网上找了个教程，自己跟着做了一遍，然后换了一个网站，爬一下别的数据，现在做一下记录，由于也是刚刚接触，所以在一些使用上可能还存在误区，欢迎大家批评指正。<br>&emsp;&emsp;<a href="http://www.weather.com.cn/weather/101250101.shtml" target="_blank" rel="noopener">http://www.weather.com.cn/weather/101250101.shtml</a><br>&emsp;&emsp;这是我们爬取信息的网址，爬取长沙未来七天的天气情况。</p>
<p>&emsp;&emsp;环境：windows10，python3.6，scrapy1.8，anaconda，chorme</p>
<h2 id="创建scrapy项目并生成相应的文件"><a href="#创建scrapy项目并生成相应的文件" class="headerlink" title="创建scrapy项目并生成相应的文件"></a>创建scrapy项目并生成相应的文件</h2><p>&emsp;&emsp;首先选择一个你的项目位置，然后在该位置下打开cmd，执行 <strong>scrapy start testSpider</strong> ,初始化一个scrapy项目，其中最后一个字段是项目名称，效果如下：<br><img src="http://q0uiq01q3.bkt.clouddn.com/3_1.png" alt=""></p>
<p>&emsp;&emsp;在PyCharm中可以查看一下目录结构：<br><img src="http://q0uiq01q3.bkt.clouddn.com/3_2.png" alt=""></p>
<p>&emsp;&emsp;这些文件的主要作用在官方文档里都有介绍。<br>&emsp;&emsp;然后我们回到cmd，根据提示进行操作，cd testSpider 切换到项目的文件夹下，执行 <strong>scrapy genspider example example.com</strong>，这里example是你的爬虫的name，是他的唯一标示，不同的爬虫的name必须不同，example.com是允许爬取的域。<br>&emsp;&emsp;我们执行&emsp;<strong>scrapy genspider weather weather.com.cn</strong>&emsp;创建一个爬虫的执行文件。执行完之后可以PyCharm中看到在spiders的文件夹下生成了一个weather.py文件：<br><img src="http://q0uiq01q3.bkt.clouddn.com/3_3.png" alt=""></p>
<p>&emsp;&emsp;文件包含一些自动生成的代码。</p>
<h2 id="分析需要爬取的网页并编码"><a href="#分析需要爬取的网页并编码" class="headerlink" title="分析需要爬取的网页并编码"></a>分析需要爬取的网页并编码</h2><p>&emsp;&emsp;我们打开那个网址，ctrl+shift+i，检查，一步一步找到我们需要的信息，最终发现，这些天气的信息都在一个如图所示的位置。<br><img src="http://q0uiq01q3.bkt.clouddn.com/3_4.png" alt=""></p>
<p>&emsp;&emsp;找到这个位置之后，我们点开一天的，信息如下图所示，因为我是在晚上写的这篇博客，看的又是第一天，所以只有最低温度，没有最高温度，我们提取 天，天气，最低温和最高温这4项信息。<br><img src="http://q0uiq01q3.bkt.clouddn.com/3_5.png" alt=""></p>
<p>&emsp;&emsp;这时候，我们需要打开项目中的items.py，写一个类来保存（封装）我们的这些数据，如下图所示。<br><img src="http://q0uiq01q3.bkt.clouddn.com/3_6.png" alt=""></p>
<p>&emsp;&emsp;下面需要我们的爬虫登场了，打开spider下的weather.py，我们下面使用BeautifulSoup来进行数据的提取。我直接贴上代码喽。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> scrapy</span><br><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line"><span class="keyword">from</span> weatherSpider.items <span class="keyword">import</span> WeatherItem</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">WeahterSpider</span><span class="params">(scrapy.Spider)</span>:</span></span><br><span class="line">    name = <span class="string">'weather'</span>		<span class="comment">#spider的名字，唯一标志</span></span><br><span class="line">    allowed_domains = [<span class="string">'weather.com.cn'</span>]		<span class="comment">#允许爬取的域</span></span><br><span class="line">    start_urls = [<span class="string">'http://www.weather.com.cn/weather/101250101.shtml'</span>]	<span class="comment">#开始爬取的起点</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">parse</span><span class="params">(self,response)</span>:</span></span><br><span class="line">        html = response.text		<span class="comment">#获得爬到的网页的HTML代码</span></span><br><span class="line"></span><br><span class="line">        soup = BeautifulSoup(html,<span class="string">'lxml'</span>)	<span class="comment">#创建一个soup对象</span></span><br><span class="line">        weather = WeatherItem()			<span class="comment">#创建一个weatherItem对象，存储爬取的信息</span></span><br><span class="line">        div_7d = soup.find(<span class="string">'div'</span>,class_=<span class="string">'c7d'</span>)	<span class="comment">#找到class为c7d的标签</span></span><br><span class="line">        <span class="keyword">if</span> div_7d <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:					<span class="comment">#如果存在</span></span><br><span class="line">            ul = div_7d.find(<span class="string">'ul'</span>)				<span class="comment">#逐步缩小范围</span></span><br><span class="line">            <span class="keyword">if</span> ul <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">                <span class="keyword">for</span> li <span class="keyword">in</span> ul.find_all(<span class="string">'li'</span>):</span><br><span class="line">                    <span class="keyword">if</span> li <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">                        weather[<span class="string">'day'</span>] = li.find(<span class="string">'h1'</span>).get_text()		<span class="comment">#取标签包含的数据</span></span><br><span class="line">                        weather[<span class="string">'wea'</span>] = li.find(<span class="string">'p'</span>).get_text()</span><br><span class="line">                        span = li.find(<span class="string">'span'</span>)</span><br><span class="line">                        <span class="keyword">if</span> span <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">                            weather[<span class="string">'highest'</span>] = span.get_text()</span><br><span class="line">                        weather[<span class="string">'lowest'</span>] = li.find(<span class="string">'i'</span>).get_text()</span><br><span class="line">                        print(weather)</span><br></pre></td></tr></table></figure>
<p>&emsp;&emsp;整体的思想就是一步一步缩小范围，逐步获得我们需要的数据。</p>
<h2 id="entryPoint-py-便捷启动"><a href="#entryPoint-py-便捷启动" class="headerlink" title="entryPoint.py 便捷启动"></a>entryPoint.py 便捷启动</h2><p>&emsp;&emsp;编写完上面的代码，在scrapy项目的根目录下执行&emsp;<strong>scrapy crawl weather</strong>&emsp;就能为了能够运行爬虫程序了，但是为了更加方便的启动爬虫，我们可以在项目根目录下编写一个entrypoint.py文件，直接在PyCharm中启动爬虫，</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> scrapy.cmdline <span class="keyword">import</span> execute</span><br><span class="line"></span><br><span class="line">execute([<span class="string">'scrapy'</span>,<span class="string">'crawl'</span>,<span class="string">'weather'</span>])</span><br></pre></td></tr></table></figure>
<p>&emsp;&emsp;执行之后就能够看到爬取的数据的结果了：<br><img src="http://q0uiq01q3.bkt.clouddn.com/3_7.png" alt=""></p>
<p>&emsp;&emsp;到这，这个简单的scrapy爬虫实战就结束了….确实很简单，但也会有成就感。</p>
<h2 id="补充"><a href="#补充" class="headerlink" title="补充"></a>补充</h2><p>&emsp;&emsp;最后补充一点，菜鸡用markdown的时候，#后面忘记加空格，导致标题显示不出来，嘿嘿嘿，抽自己一下。</p>
]]></content>
      <categories>
        <category>学习</category>
      </categories>
      <tags>
        <tag>Scrapy</tag>
        <tag>爬虫</tag>
      </tags>
  </entry>
  <entry>
    <title>git@git.coding.net: Permission denied (publickey)的解决办法</title>
    <url>/git-git-coding-net-Permission-denied-publickey-%E7%9A%84%E8%A7%A3%E5%86%B3%E5%8A%9E%E6%B3%95.html</url>
    <content><![CDATA[<p>&emsp;&emsp;报错如下：<br><img src="http://q0uiq01q3.bkt.clouddn.com/pd.png" alt=""> </p>
<p>&emsp;&emsp;但是我已经在站点配置文件配置好，并且已经在coding的项目中添加了公钥，但是请求连接时还是出现了问题。<br>&emsp;&emsp;解决办法：</p>
<figure class="highlight angelscript"><table><tr><td class="code"><pre><span class="line"><span class="number">1.</span>执行   eval `ssh-agent`</span><br><span class="line"><span class="number">2.</span>执行   ssh-add ~/.ssh/rsa</span><br><span class="line"><span class="number">3.</span>执行   ssh-add –l</span><br><span class="line"><span class="number">4.</span>重新尝试连接  ssh -T <span class="symbol">git@</span>e.coding.net</span><br></pre></td></tr></table></figure>
<p>&emsp;&emsp;之前一直使用的 ssh -T <a href="mailto:git@git.coding.net" target="_blank" rel="noopener">git@git.coding.net</a> 结果执行完上面三个指令还是连接不上，后来在Coding的官方文档中看到这个<br><img src="http://q0uiq01q3.bkt.clouddn.com/coding.png" alt=""></p>
<p>&emsp;&emsp;原来是连接指令错误….<br>&emsp;&emsp;这样就成功连接了。</p>
<p><img src="http://q0uiq01q3.bkt.clouddn.com/success.png" alt=""></p>
]]></content>
      <categories>
        <category>hexo博客搭建</category>
      </categories>
      <tags>
        <tag>hexo</tag>
      </tags>
  </entry>
  <entry>
    <title>hexo搭建博客时遇到的问题</title>
    <url>/hexo%E6%90%AD%E5%BB%BA%E5%8D%9A%E5%AE%A2%E6%97%B6%E9%81%87%E5%88%B0%E7%9A%84%E9%97%AE%E9%A2%98.html</url>
    <content><![CDATA[<h2 id="hexo-g-执行后不生成index-html"><a href="#hexo-g-执行后不生成index-html" class="headerlink" title="hexo g 执行后不生成index.html"></a>hexo g 执行后不生成index.html</h2><p>&emsp;&emsp;这里也只是提出几种可能性:</p>
<ul>
<li>我当时执行 npm install 之后重新执行一遍就可以了</li>
<li>朋友发现自己多包含了一个头文件</li>
</ul>
<h2 id="修改背景图片"><a href="#修改背景图片" class="headerlink" title="修改背景图片"></a>修改背景图片</h2><p>&emsp;&emsp;next主题更新后，就没有了custom.styl文件，当时网上很多教程都是使用这个文件设置背景图片，但是新版本的next也提供了用户自定义的文件，首先需要在next主题的配置文件中启用：</p>
<figure class="highlight ruby"><table><tr><td class="code"><pre><span class="line"><span class="symbol">custom_file_path:</span></span><br><span class="line">  <span class="comment">#head: source/_data/head.swig</span></span><br><span class="line">  <span class="comment">#header: source/_data/header.swig</span></span><br><span class="line">  <span class="comment">#sidebar: source/_data/sidebar.swig</span></span><br><span class="line">  <span class="comment">#postMeta: source/_data/post-meta.swig</span></span><br><span class="line">  <span class="comment">#postBodyEnd: source/_data/post-body-end.swig</span></span><br><span class="line">  <span class="comment">#footer: source/_data/footer.swig</span></span><br><span class="line">  <span class="comment">#bodyEnd: source/_data/body-end.swig</span></span><br><span class="line">  <span class="comment">#variable: source/_data/variables.styl</span></span><br><span class="line">  <span class="comment">#mixin: source/_data/mixins.styl</span></span><br><span class="line">  <span class="symbol">style:</span> source/_data/styles.styl</span><br></pre></td></tr></table></figure>
<p> &emsp;&emsp;将最后一个的注释取消，然后到blog的source文件夹下(<strong>注意，是blog的source，不是next的source</strong>)创建这个文件，将设置背景图片的css放进去，<br> <figure class="highlight css"><table><tr><td class="code"><pre><span class="line"><span class="selector-tag">body</span> &#123;</span><br><span class="line"> <span class="attribute">background-image</span>:<span class="built_in">url</span>(/images/header.jpg); </span><br><span class="line"> <span class="attribute">background-repeat</span>: no-repeat; </span><br><span class="line"> <span class="attribute">background-attachment</span>:fixed; </span><br><span class="line"> <span class="attribute">background-position</span>:<span class="number">50%</span> <span class="number">50%</span>;</span><br><span class="line"> <span class="attribute">background-size</span>:cover;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><br>&emsp;&emsp;还有注意将图片放在next的source的images中，至于为什么这么迷我也不清楚….<br>&emsp;&emsp;这里顺便说一下，设置背景透明度的css也直接放在这个文件中就可以了，透明度的效果可以根据自己的喜好调节，1是不透明，0是全透明，我是小透明，不是很聪明。</p>
<figure class="highlight css"><table><tr><td class="code"><pre><span class="line"> <span class="selector-class">.main-inner</span> &#123; </span><br><span class="line">    <span class="attribute">opacity</span>: <span class="number">0.9</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="点击头像回到主页"><a href="#点击头像回到主页" class="headerlink" title="点击头像回到主页"></a>点击头像回到主页</h2><p>&emsp;&emsp;确实哈，鼠标放在头像上就想去点，虽然卵用不大，但这个功能必须得有啊。<br>&emsp;&emsp;网上教程用不了，在sidebar.swig文件中没有头像的标签，于是我就把附近的文件找了找，反正思路就是加个跳转，管他在哪里，只要能找到，加上看他跳不跳。<br>&emsp;&emsp;终于，在\next\layout_partials\sidebar下找到了site-overview.swig文件，找到</p>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">img</span> <span class="attr">class</span>=<span class="string">"site-author-image"</span> <span class="attr">itemprop</span>=<span class="string">"image"</span> <span class="attr">alt</span>=<span class="string">"&#123;&#123; author &#125;&#125;"</span> <span class="attr">src</span>=<span class="string">"&#123;&#123; url_for(theme.avatar.url or theme.images + '/header.jpg') &#125;&#125;"</span>&gt;</span></span><br></pre></td></tr></table></figure>
<p>&emsp;&emsp;在这段代码的开始前面和结束后面分别加上第一行和第二行：</p>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">a</span> <span class="attr">href</span>=<span class="string">"/"</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">a</span>&gt;</span></span><br></pre></td></tr></table></figure>
<p>&emsp;&emsp;记得将img标签的src改成自己头像路径。</p>
]]></content>
      <categories>
        <category>hexo博客搭建</category>
      </categories>
      <tags>
        <tag>hexo</tag>
        <tag>next主题美化</tag>
      </tags>
  </entry>
</search>
